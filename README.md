Predicting Metabolic Cost from Wearable Sensor Data
Project for CS229: Machine Learning Project Duration: September 29, 2025 - October 15, 2025

1. Project Overview
This project tackles the challenge of predicting the metabolic cost of human locomotion using data from wearable sensors. The goal is to develop a machine learning model that can accurately estimate metabolic rate from gait kinematics and muscle activity (EMG), which has significant applications in exoskeleton control, rehabilitation, and assistive device optimization.

We compare the performance of a regularized linear model (Lasso) against a non-linear model (a single-layer Neural Network) to determine the most effective approach for this complex regression task. The pipeline involves extracting data from a complex .mat file, generating synthetic features, preprocessing the data, and training/evaluating the models using k-fold cross-validation.

The final results demonstrate that a Neural Network significantly outperforms the linear model, indicating the presence of complex, non-linear relationships in the data.

2. Repository Contents
This repository contains the full source code and data required to reproduce the project's findings.

data/

P01.mat: The raw, nested MATLAB file containing the original sensor data from various gait trials.

synthetic_data.csv: A sample CSV file used to define the required data structure and column order for the pipeline.

src/

generate_data.py: A robust Python script designed to handle the primary data extraction challenge. It iteratively parses the complex P01.mat file, extracts all EMG data chunks, generates synthetic gait parameters, and creates the final, unified realistic_synthetic_data.csv dataset.

data_processing.py: A script that takes the generated dataset, performs Z-score normalization on all features, and saves the preprocessed data.

model_train.py: The final script in the pipeline. It loads the preprocessed data and trains three models: a baseline Lasso regressor, a Neural Network with hyperparameter tuning, and a PCA+NN model. It outputs the final performance metrics to results.json and generates a performance comparison plot.

output/ (These files will be generated by the scripts)

realistic_synthetic_data.csv: The large, combined dataset created by generate_data.py.

preprocessed.csv: The normalized dataset created by data_processing.py.

results.json: The final JSON file containing the MSE scores and best hyperparameters for each model.

results_performance.png: A bar chart visualizing the final model performances.

3. Setup and Execution Instructions
Follow these steps to set up the environment and run the complete project pipeline.

Step 1: Clone the Repository
Clone this private GitHub repository to your local machine.

Step 2: Set Up the Python Environment
It is highly recommended to use a virtual environment.

# Create a virtual environment
python -m venv venv

# Activate the environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

Step 3: Install Required Libraries
This project requires several scientific computing libraries. The itemset was removed... error we encountered indicates a conflict with NumPy 2.0. The following command installs versions that are known to be compatible.

pip install "numpy<2.0" scipy pandas scikit-learn matplotlib

Step 4: Run the Full Pipeline
Execute the three main Python scripts in the correct order from your terminal. Ensure your terminal's working directory is the root of the project folder.

1. Generate the Dataset:
This script will read the P01.mat file and create the realistic_synthetic_data.csv file. This is the most time-consuming step but will provide progress updates.

python generate_data.py

2. Preprocess the Data:
This will normalize the dataset you just created and save it as preprocessed.csv. This step is very fast.

python data_processing.py realistic_synthetic_data.csv --out preprocessed.csv

3. Train the Models:
This will run all model training and evaluation tasks and produce the final results.json and results_performance.png files.

python model_train.py preprocessed.csv --out results.json

After these commands complete, the results.json file will contain the final performance metrics for each model, summarizing the project's findings.
